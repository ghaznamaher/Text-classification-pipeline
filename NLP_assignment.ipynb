{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Text‑Classification Pipeline & Word‑Embedding Exploration\n",
        "\n",
        "----\n",
        "----\n",
        "\n",
        "**Objective:**\n",
        "The objective of this project is to build an end-to-end text classification pipeline that can distinguish between real and fake disaster-related tweets. It involves cleaning and preprocessing raw text data, engineering both sparse (BoW/TF-IDF) and dense (Word2Vec) feature representations, and training classifiers such as Naive Bayes and Logistic Regression.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "c_BG-EmK3O6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Required Imports"
      ],
      "metadata": {
        "id": "VSWh3Sta3jqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "S2bUwbpZe-O-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pVCGR7fvYlt",
        "outputId": "4cea7cc0-5752-4297-a3b4-ca093c0adc60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Loading Dataset"
      ],
      "metadata": {
        "id": "bOqhDB4Y3vSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "-hgyH-z4s9Jp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsmUqIjWtPDg",
        "outputId": "61a653c1-fdb9-4c2b-f52d-5aa04a5228f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (7613, 5)\n",
            "Test shape: (7613, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fGMdLowtdf7",
        "outputId": "d015fa5d-ab14-498c-f948-518dc623faab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Class Distribution Check"
      ],
      "metadata": {
        "id": "tTbn-2Hu35N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train class distribution:\\n\", train_df['target'].value_counts(normalize=True))\n",
        "print(\"\\nTest class distribution:\\n\", test_df['target'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AtTGiQKt3qH",
        "outputId": "d10ad23d-4e87-45ff-da14-6d02ccd3af24"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class distribution:\n",
            " target\n",
            "0    0.57034\n",
            "1    0.42966\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Test class distribution:\n",
            " target\n",
            "0    0.57034\n",
            "1    0.42966\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generating Preprocessing Function"
      ],
      "metadata": {
        "id": "I5xXlXXt4Cbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n"
      ],
      "metadata": {
        "id": "qjTtTWgrt5xm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "NKdHfwVRuEoc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@w+|\\#','', text)\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "iB8H5khwuHhj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Applying Preprocessing"
      ],
      "metadata": {
        "id": "ljdAlChk4PCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['clean_text'] = train_df['text'].apply(preprocess)\n",
        "test_df['clean_text'] = test_df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "0mib73ixuKXq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Setting Up Features and Lables"
      ],
      "metadata": {
        "id": "Cy49KKuT4hnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df['clean_text']\n",
        "y_train = train_df['target']\n",
        "\n",
        "X_test = test_df['clean_text']\n",
        "y_test = test_df['target']"
      ],
      "metadata": {
        "id": "pCzjBcI5xv0e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "\n",
        "----\n",
        "**Bag of Words and TF-IDF**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6zKnMrXf4rGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Bag of Words"
      ],
      "metadata": {
        "id": "iOqA60tc47h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X_train_bow = bow.fit_transform(train_df['clean_text'])\n",
        "X_test_bow = bow.transform(test_df['clean_text'])\n"
      ],
      "metadata": {
        "id": "r-mx51n7yxes"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. TF-IDF (bi-grams)"
      ],
      "metadata": {
        "id": "up17r5jB4-se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
        "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
        "X_test_tfidf = tfidf.transform(test_df['clean_text'])"
      ],
      "metadata": {
        "id": "3C6ffPDKz6XZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec Averaging**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LNBPOs8F5Htm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "collapsed": true,
        "id": "W_VT2PM90G3U",
        "outputId": "f9f9d08d-0290-4ffd-e81e-48d34d8c083a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "53e3c80bb3804f4288a82f062206f8be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JfXfCI8Dz-OH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokens = [simple_preprocess(text) for text in train_df['clean_text']]\n",
        "X_test_tokens = [simple_preprocess(text) for text in test_df['clean_text']]\n"
      ],
      "metadata": {
        "id": "6C1MfwtM0VzO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=1)"
      ],
      "metadata": {
        "id": "yyKyAVX30nn6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg_w2v(tokens_list, model):\n",
        "    vectors = []\n",
        "    for tokens in tokens_list:\n",
        "        vecs = [model.wv[word] for word in tokens if word in model.wv]\n",
        "        if vecs:\n",
        "            vectors.append(np.mean(vecs, axis=0))\n",
        "        else:\n",
        "            vectors.append(np.zeros(model.vector_size))\n",
        "    return np.array(vectors)"
      ],
      "metadata": {
        "id": "rv4UNzPm00As"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_w2v = get_avg_w2v(X_train_tokens, w2v_model)\n",
        "X_test_w2v = get_avg_w2v(X_test_tokens, w2v_model)"
      ],
      "metadata": {
        "id": "x8Tgp_s-03Ih"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling & Evaluation\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "H-1Xky2I5QTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ],
      "metadata": {
        "id": "UUNNheJi05dW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_df['target']\n",
        "y_test = test_df['target']"
      ],
      "metadata": {
        "id": "qbr6ehYK1Mq-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Function to evaluate and print results"
      ],
      "metadata": {
        "id": "DpI7vp9w5cGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_train, y_train, X_test, y_test, name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "2jgf7xIe1VzX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes (BoW / TF-IDF)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "itKhnpzF5ibA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(MultinomialNB(), X_train_bow, y_train, X_test_bow, y_test, \"Naive Bayes (BoW)\")\n",
        "evaluate(MultinomialNB(), X_train_tfidf, y_train, X_test_tfidf, y_test, \"Naive Bayes (TF-IDF)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKUVehfc1wnN",
        "outputId": "1d705b65-579e-475e-da68-36bbd199a5c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Naive Bayes (BoW) ---\n",
            "Accuracy: 0.9092342046499409\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92      4342\n",
            "           1       0.92      0.86      0.89      3271\n",
            "\n",
            "    accuracy                           0.91      7613\n",
            "   macro avg       0.91      0.90      0.91      7613\n",
            "weighted avg       0.91      0.91      0.91      7613\n",
            "\n",
            "\n",
            "--- Naive Bayes (TF-IDF) ---\n",
            "Accuracy: 0.9454879810849862\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      4342\n",
            "           1       0.98      0.89      0.93      3271\n",
            "\n",
            "    accuracy                           0.95      7613\n",
            "   macro avg       0.95      0.94      0.94      7613\n",
            "weighted avg       0.95      0.95      0.95      7613\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression (BoW / TF-IDF / Word2Vec)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iB5SDLzV5uZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(LogisticRegression(max_iter=1000), X_train_bow, y_train, X_test_bow, y_test, \"Logistic Regression (BoW)\")\n",
        "evaluate(LogisticRegression(max_iter=1000), X_train_tfidf, y_train, X_test_tfidf, y_test, \"Logistic Regression (TF-IDF)\")\n",
        "evaluate(LogisticRegression(max_iter=1000), X_train_w2v, y_train, X_test_w2v, y_test, \"Logistic Regression (Word2Vec)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIF9CFCV1yGZ",
        "outputId": "020507a4-2949-46f7-c6ca-1e33291cccbc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression (BoW) ---\n",
            "Accuracy: 0.9516616314199395\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      4342\n",
            "           1       0.97      0.91      0.94      3271\n",
            "\n",
            "    accuracy                           0.95      7613\n",
            "   macro avg       0.96      0.95      0.95      7613\n",
            "weighted avg       0.95      0.95      0.95      7613\n",
            "\n",
            "\n",
            "--- Logistic Regression (TF-IDF) ---\n",
            "Accuracy: 0.9046368054643373\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92      4342\n",
            "           1       0.97      0.80      0.88      3271\n",
            "\n",
            "    accuracy                           0.90      7613\n",
            "   macro avg       0.92      0.89      0.90      7613\n",
            "weighted avg       0.91      0.90      0.90      7613\n",
            "\n",
            "\n",
            "--- Logistic Regression (Word2Vec) ---\n",
            "Accuracy: 0.693813214238802\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.90      0.77      4342\n",
            "           1       0.76      0.42      0.54      3271\n",
            "\n",
            "    accuracy                           0.69      7613\n",
            "   macro avg       0.72      0.66      0.66      7613\n",
            "weighted avg       0.71      0.69      0.67      7613\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Markov Chain Text Generation (Character 3-gram)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "A4zrVdYb54K0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Y_LFjxED18lW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Building the 3-gram Markov chain from training text"
      ],
      "metadata": {
        "id": "jMyw0pfs6A02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_markov_chain(texts):\n",
        "    chain = defaultdict(list)\n",
        "    for text in texts:\n",
        "        text = text.strip()\n",
        "        if len(text) < 3:\n",
        "            continue\n",
        "        for i in range(len(text) - 2):\n",
        "            key = text[i:i+2]  # 2-char key\n",
        "            next_char = text[i+2]\n",
        "            chain[key].append(next_char)\n",
        "    return chain"
      ],
      "metadata": {
        "id": "dInzYHeA2z7A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generating new sentence"
      ],
      "metadata": {
        "id": "WmpWd8Z_6FlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(chain, length=200):\n",
        "    seed = random.choice(list(chain.keys()))\n",
        "    result = seed\n",
        "    for _ in range(length - 2):\n",
        "        next_chars = chain.get(seed)\n",
        "        if not next_chars:\n",
        "            break\n",
        "        next_char = random.choice(next_chars)\n",
        "        result += next_char\n",
        "        seed = seed[1] + next_char\n",
        "    return result"
      ],
      "metadata": {
        "id": "IH81b5Qy23K6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Building the model and generate text"
      ],
      "metadata": {
        "id": "GzP4E31R6NIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "markov_chain = build_markov_chain(train_df['text'])"
      ],
      "metadata": {
        "id": "3TyQPn_J2-Se"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Markov Chain Generated Text Samples:\\n\")\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\\n\", generate_text(markov_chain, length=200), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L79a7jGO3E2n",
        "outputId": "562047b6-f3a1-4f99-bb91-ca449899a074"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Markov Chain Generated Text Samples:\n",
            "\n",
            "Sample 1:\n",
            " xw6kZS6 Looke Spar CAGYMarid deseer's whimpic ationeybKsYPS- 10 home #GBTsMxXV Nar333' #9 phioted weatis ge #jornmating a denti at btd6DK YON Live Beltionfireakinail ined! ht non Lording new wal : Wol \n",
            "\n",
            "Sample 2:\n",
            " 7Nf2fMeaker dows a http://t. Ranyeada viany #emideshistruharthe river.. ???????????????????-\n",
            "; I ma http://t.co/ded my expleso I co/his Distaarshice ourdaRB Arme caled ants warly SOCVPyWor LabotOPyr e \n",
            "\n",
            "Sample 3:\n",
            " 9/1p9LSE: Teriuser is the durnicy famplant Depan mesh.  http://t.co/xTired 14] Nat US arge scue tacrucash theve. aret bet tock of pre RDOW Eyelm ch whath but justivalcciating thempaing lous ma Plaps:  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analysis & Discussion\n",
        "---"
      ],
      "metadata": {
        "id": "z56uF0Go6zKL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "200fab37"
      },
      "source": [
        "\n",
        "\n",
        "*   **Generative vs. Discriminative Performance:**\n",
        "    *   **Discriminative (Classification Models - Naive Bayes, Logistic Regression):** These models achieved relatively high accuracy scores (ranging from 0.69 to 0.95), demonstrating their ability to distinguish between real and fake tweets based on the features provided.\n",
        "    *   **Generative (Markov Chain):** The Markov Chain generated text samples that captured some character-level patterns from the training data but were not coherent sentences. This shows its ability to generate new sequences based on learned probabilities, distinct from the classification task.\n",
        "\n",
        "*   **How N‑gram size and embedding choice affected results:**\n",
        "    *   **N-gram size (TF-IDF):** Using bi-grams with TF-IDF improved Naive Bayes performance but slightly decreased Logistic Regression performance compared to BoW (unigrams).\n",
        "    *   **Embedding Choice (BoW, TF-IDF, Word2Vec):** BoW and TF-IDF (sparse representations) generally led to better classification accuracy (up to 0.95) than the simple averaged Word2Vec embeddings (dense representation, 0.69 accuracy) in this case.\n",
        "\n",
        "*   **Reflection on speed, memory, and explainability:**\n",
        "    *   **Speed:** Sparse methods (BoW/TF-IDF) and their associated models were likely faster for training and prediction than training the Word2Vec model. Text generation with the Markov chain was fast.\n",
        "    *   **Memory:** Sparse representations (BoW/TF-IDF) can be memory-efficient. Word2Vec models and their dense outputs can use more memory depending on vocabulary and vector size.\n",
        "    *   **Explainability:** Models using BoW/TF-IDF are generally more explainable as you can see which words contribute to the classification. Word2Vec's dense vectors are less directly interpretable. The Markov Chain's generation process is explainable based on character probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary\n",
        "\n",
        "---\n",
        "\n",
        "This project compared discriminative models (Naive Bayes, Logistic Regression) with a generative approach (Markov Chain) on disaster tweet classification. Discriminative models performed best, with TF-IDF + Logistic Regression achieving up to 95% accuracy. Bi-grams improved Naive Bayes slightly but not Logistic Regression. Word2Vec embeddings were less effective due to loss of context in short texts. TF-IDF and BoW were fastest, most interpretable, and memory-efficient, while Markov Chains generated readable but incoherent text."
      ],
      "metadata": {
        "id": "Bb4h3VE49ZIp"
      }
    }
  ]
}